# 操作系统导论

## 参考资料

- 操作系统导论

## 操作系统介绍

- 下详叙

## 虚拟化

### CPU 虚拟化

- 通过时分共享实现

#### 进程

- 进程是程序的一次执行实例, 拥有独立的地址空间, 寄存器状态, 以及其他资源
- 系统会维护一个进程表, 记录所有进程的信息
- 状态
    - 初始
    - 运行
    - 就绪
    - 阻塞
    - 最终 (僵尸进程, 用于让父亲进程获取子进程的退出状态)
- 创建
    - 在进程表中分配一个新条目
    - 惰性加载程序的代码段和数据段
    - 分配并初始化运行时栈区与堆区
    - 初始化资源, 如标准输入输出的文件描述符
    - 清楚寄存器
    - 转移控制权
- 销毁
- 等待
- 其他控制

#### 进程 API

- `fork()`
    - 复制当前进程为子进程, 父子都从该调用返回继续执行
    - 子进程返回 0, 父进程返回子进程 ID
- `wait()`
    - 阻塞当前进程, 直到某个子进程退出
    - 返回退出的子进程 ID
- `exec()`
    - 用一个新程序替换当前进程的代码段和数据段
    - 重新初始化堆区和栈区
- 如此奇怪的设计是为了方便在 `fork()` 与 `exec()` 之间插入其他操作, 如重定向标准输入输出

#### 受限直接执行

- 为了提高性能, 允许用户进程直接在 CPU 上运行, 但还是要受限于某些规则
- 区分用户态与内核态
- 提供陷入与从陷阱返回的硬件原语
    - 在每个进程的内核栈中保存现场
    - 内核在启动时设置陷阱表

#### 进程间切换

- 系统可以等待任意系统调用, 或者用户程序进行非法操作
    - `yield()` 什么也不做, 只是让出 CPU
- 也可以通过时钟中断, 时钟中断也就是为了操作系统维护控制权而设计的
    - 由操作系统启动时钟
    - 触发时会调用内核中的时钟中断处理程序
- 上下文切换
    - 和保存现场类似但不一样
    - 是由操作系统主导的存储在进程结构中的现场保存与恢复

#### 进程调度

- 越了解工作负载, 越能设计出好的调度算法
- $\text{周转时间} = \text{完成时间} - \text{到达时间}$ 性能指标
    - 性能和公平在调度中往往是矛盾的
- FIFO
    - 先到先工作
    - 出现长作业时, 短作业等待时间过长 (护航效应)
- SFJ 最短作业优先
    - 优先调度估计运行时间最短的作业
    - 需要预知作业运行时间, 实际中难以实现
- 现在考虑任务不同时间到达
- STCF 最短完成时间优先
    - 抢占式的 SJF
    - 新到达的短作业可以抢占正在运行的长作业
- $\text{响应时间} = \text{第一次运行时间} - \text{到达时间}$ 交互式系统重要指标
- RR 时间片轮转
    - 每个进程分配一个时间片, 时间片用完后切换到下一个进程
    - 时间片过大接近 FIFO, 过小则切换开销过大
    - 但对于周转时间非常差
- 现在考虑 IO 与运行时间不可知
- MLFQ 多级反馈队列
    - 基本思想
        - IO 密集型进程提升优先级, CPU 密集型进程降低优先级
        - 多个就绪队列, 每个队列有不同优先级, 队列内的进程优先级相同
        - 优先级高的队列先调度, 队列中进程采用 RR 调度
    - 方案
        - 新到达的进程进入最高优先级队列
        - 时间片用完后降低优先级, 但若在时间片内主动释放 CPU 则保持优先级
    - 对于 IO 密集型进程太友好, 可能导致 CPU 密集型进程饥饿
        - 每过一段时间, 将所有进程提升到最高优先级队列 (核心问题是具体多长时间)
    - 但是仍然会被恶意进程欺骗
        - 例如一个进程不断地在时间片内释放 CPU, 永远保持最高优先级
        - 解决方法是主动释放 CPU 不重置时间片
- 如果我们不考虑周转时间与响应时间, 而是确保每个工作获得一定比例的 CPU 时间
- 彩票调度
    - 每个进程根据彩票数量获得相应比例调度概率
    - 每次调度时, 系统随机抽取彩票, 持有该彩票的进程获得 CPU 时间
    - 彩票货币
        - 用户分配给进程彩票, 系统自动根据全局彩票池调度
    - 彩票转让
        - 进程可以将彩票转让给其他进程 (我依赖你, 我给你彩票)
    - 彩票通胀
        - 进程相互信任时, 可临时自发行彩票
    - 彩票中奖是随机的, 若为了公平性, 可引入行程, 使用步长调度
        - 用一个大数处以每个进程的彩票数, 结果作为该进程的步长
        - 每次调度一个进程时, 将该进程的行程加上步长
        - 每次调度时选择行程最小的进程

#### 多处理器调度

- 缓存亲和性: 尽可能将进程保持在同一个 CPU 上
- SQMS 单队列多处理器调度
    - 所有 CPU 共享一个就绪队列
    - 优点: 简单, 负载均衡
    - 缺点: 缓存亲和性差, 锁开销大
- MQMS 多队列多处理器调度
    - 每个 CPU 有自己的就绪队列
    - 优点: 缓存亲和性好, 锁开销小
    - 缺点: 负载均衡差 (但解决它的开销显著小于解决锁开销)
    - 解决方法
        - 迁移: 将某些进程从一个 CPU 队列迁移到另一个 CPU 队列
        - 具体实现为工作窃取: 空闲 CPU 从其他 CPU 窃取进程
- Linux 系统的实现, 三足鼎立
    - O(1) 调度器: 基于 MQMS + MLFQ
    - CFS 调度器: 基于虚拟运行时间 + 红黑树 (完全公平调度器)
    - BFS 调度器: 基于 SQMS + EEVEF (最早最合适虚拟截止时间优先算法)

### 内存虚拟化

#### 地址空间

- 最早使用时分复用, 调度的进程才进入内存, 否则驻留在磁盘上
    - 太慢了, 所以内存够用的时候就不换出, 安全性又成问题
- 使用虚拟内存: 实现透明, 效率与保护
- `brk` 系统调用用来分配堆空间
    - 调整程序分断 (堆结束) 的位置

#### 地址转换

- 基于硬件的地址转换, 将虚拟地址转换为物理地址
- 需要解决的第一个问题, 如何将基于虚拟地址编写的程序载入到不同物理地址运行
- 动态重定位 (硬件实现, 对应的软件实现就是静态重定位)
    - 使用寄存器保存基址 (基址寄存器) 与界限 (界限寄存器)
    - 每次内存访问时, 将虚拟地址加上基址寄存器的值作为物理地址, 但虚拟地址不允许超过界限寄存器的值
    - 缺点: 只能实现连续分配, 内存碎片严重

#### 分段

- 栈与堆中间的内存未被使用, 导致大量浪费 (内部碎片)
- 考虑引入更多的基址与界限对, 每个分段一对
- 如何了解虚拟地址对应哪个分段
    - 将虚拟地址划分为两部分, 高位作为分段号, 低位作为段内偏移
    - 或者根据地址来源判断 (PC / 栈指针 / 其他)
- 栈在物理内存中也是向下增长的, 所以计算偏移量时要特殊处理
- 段也需要一个段表去维护权限, 基址与界限, 增长方向等信息
- 甚至堆空间的内部碎片也无法避免

#### 空闲空间管理

- 最初空闲列表 (链表) 维护空闲空间起始地址与大小, 不断分割与合并
    - 但是不能记录已分配空间的信息 (用于释放)
    - 链表节点本身就存储在空闲内存块内部, 不需要额外的内存 (`size` + `next`)
- 头块
    - 在每个分配块的前面存储一个头块, 记录该块的大小与魔法数 (完整性校验)
    - 返回给用户的指针是头块后面的地址
    - 被隐式创建, 使用, 释放, 用户不可见
- 使用 `mmap()` 或 `sbrk` 向操作系统申请内存
- 剩余空间不足时会尝试向操作系统申请更多内存, 还不够则返回 `NULL`
- 存在外部碎片问题, 尽可能优化分配算法
    - 最优分配: 分配最小的足够空间 (遍历开销大)
    - 最坏匹配: 分配最大的足够空间 (幻想避免产生过小碎片, 现实很骨感, 遍历开销大 + 没啥效果)
    - 首次匹配: 从头开始找到第一个足够空间 (速度快, 碎片更容易合并)
    - 循环首次匹配: 记录上次分配位置, 从该位置开始查找 (避免总是从头开始, 速度更快)
    - 厚块分配程序: 将空闲块按大小分类, 只在对应类别中查找 (减少遍历开销)
    - 伙伴算法: 将内存划分为若干 2 的幂次方大小的块, 分配时向上取整, 回收时合并相邻空闲块
- 现实中往往结合多种算法 + 使用更高级的数据结构 (如平衡树) 来管理空闲空间

#### 分页

- 部分见硬件软件接口
- 分段式将空间划分为若干不同大小的段, 分页式将空间划分为固定大小的页
- 页表设计
    - 多级页表
    - 每一项都是 $8$ 字节
    - 包括物理页号, 占 $40$ 位
    - 有效位, 缺不缺页
    - 读写位, 只能限制用户态
    - 特权位
    - 禁止执行位
    - 脏位, 是否被写过, 决定是否需要写回磁盘
        - 先于缓存的脏位, 写回磁盘前会先从缓存写回主存
    - 缓存位, 告诉 CPU 不用看 Cache 直接读写内存
    - 参考位, 是否被访问过, 用于页面置换算法
- 单级页表流程
    - 掩码 + 移位获得虚拟页号
    - 根据页表基址与虚拟页号计算页表项地址
    - 读取页表项, 物理页号 + 偏移量获得物理地址
    - 也就是翻倍的内存访问开销

#### TLB 与页表

- TLB 是页表的 Cache
    - 在 CPU 内部的内存管理单元实现, 速度非常快
    - 对其访问是纯硬件的, 操作系统配置一下页大小 (必须是 $2$ 的幂次方) 和页表位置即可
    - TLB 命中时直接拿到物理地址
    - TLB 失效时查页表, 再加载到 TLB
- TLB 表项
    - 虚拟页号
    - 物理页号
    - 保护位: 读 / 写 / 执行
    - 有效位: 表示缓存是否有效
    - ASID (地址空间标识符)
        - 用于区分不同进程的同一虚拟页号
        - 避免切换进程时清空 TLB 的开销
    - 脏位: 是否被写过
    - 全局位: 是否在所有进程中都有效 (忽略 ASID)
- 线性页表实在太大
    - 大页, 或者至少变长页
    - 分段 + 分页, 页表中只需要保存该段界限大小的地址空间的项
- 多级页表
    - 将线性页表切分为页大小的块, 建立页目录记录这些块的位置
    - 如果一个块内所有页表项都是无效的, 则不分配该块
    - 页目录项 (PDE)
        - 有效位: 指示该页表块是否存在
        - 物理页号: 指向该页表块的物理页号
    - 可以继续多级切分, 会有性能开销, 用 TLB 掩盖
        - 目的是每一级页表都能放在一个页内 (灵活分配内存)
- 反向页表
    - 全局仅有一张页表, 每个页表项为一个物理页框
    - 每个项中保存该页框对应的虚拟页号与进程 ID
    - 通过哈希表建立索引

#### 页面置换

- 将不常用的页换出到磁盘, 释放内存给其他页使用
    - 一般使用 swap 分区
    - 但如果加载的页从不会被修改 (如程序代码页), 则直接覆盖, 下次再从文件加载即可
- 页错误: 访问的页不在内存中
    - 根据页表项的存在位判断
    - 根据页表项中的磁盘地址将页读入内存
    - 内存已满时, 需要选择一个页换出 (页面置换算法)
- 系统一般规定一个最大内存使用量, 保证内存中始终有一定数量的空闲页
    - 通过页面清理程序后台运行, 将脏页写回磁盘, 并将不常用页换出
- 页面置换算法
    - 最优替换
        - 换出未来最长时间内不会被访问的页
        - 理论上最优, 实际中不可实现
    - FIFO 先进先出
        - 换出最早进入内存的页
        - 神奇的 Belady 异常: 增加页框反而增加缺页率, 原因是 FIFO 不具备栈特性 (大小为 $n + 1$ 的缓存一定包含大小为 $n$ 的缓存的内容)
    - 随机算法
        - 随机选择一个页换出
    - LRU 最近最少使用
        - 换出最长时间未被访问的页
    - LFU 最不常用
        - 换出访问次数最少的页
- 近似 LRU 算法
    - LRU 实现开销较大, 需要记录每个页的访问时间, 所以使用近似算法
    - 为每个页维护一个使用位, 硬件在每次访问页时将参考位置 1
    - 时钟算法
        - 将页表项按环形链表连接
        - 使用一个指针指向当前候选页
        - 每次需要换出页时, 检查指针指向的页的参考位
            - 若为 0, 则换出该页
            - 若为 1, 则将参考位清 0, 指针后移, 继续检查下一个页
    - 没有参考位是近似时钟算法
        - 每个进程使用 FIFO
        - 被换出的页放入全局的干净页列表或脏页列表末尾
        - 如果进程再次访问该页, 则可以直接从列表中取回, 不需要读磁盘
        - 只有当列表满时, 列表头的页才会被真正丢弃或写入磁盘
    - 考虑到写操作的开销, 可以引入脏位, 更优先换出未被修改的页
        - 批处理优化

#### VAX/VMS 虚拟内存系统

- 地址空间的高半部分是内核, 所有进程共享同一个 S 段映射
    - 上下文切换时, 不需要更改 S 段的映射
    - 内核可以直接访问用户空间的数据
    - 内核不是独立的实体, 而是所有进程的一部分
- 按需置零
    - 申请内存时, 不立即分配物理页, 而是等到第一次访问时才分配并清零
- 写时复制
    - `fork()` 时不复制内存, 而是共享, 只在写时才复制
- 空指针保护
    - 保留地址空间的低端不映射任何物理页, 防止空指针引用
- 防止恶意进程占用过多内存
    - 给每个进程设定一个驻留集大小上限, 只能踢掉自己进程的页, 防止某个进程占用过多内存

## 并发控制

## 持久化
