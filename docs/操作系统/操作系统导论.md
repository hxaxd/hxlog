# 操作系统导论

## 参考资料

- 操作系统导论

## 操作系统介绍

- 下详叙

## 虚拟化

### CPU 虚拟化

- 通过时分共享实现

#### 进程

- 进程是程序的一次执行实例, 拥有独立的地址空间, 寄存器状态, 以及其他资源
- 系统会维护一个进程表, 记录所有进程的信息
- 状态
    - 初始
    - 运行
    - 就绪
    - 阻塞
    - 最终 (僵尸进程, 用于让父亲进程获取子进程的退出状态)
- 创建
    - 在进程表中分配一个新条目
    - 惰性加载程序的代码段和数据段
    - 分配并初始化运行时栈区与堆区
    - 初始化资源, 如标准输入输出的文件描述符
    - 清楚寄存器
    - 转移控制权
- 销毁
- 等待
- 其他控制

#### 进程 API

- `fork()`
    - 复制当前进程为子进程, 父子都从该调用返回继续执行
    - 子进程返回 0, 父进程返回子进程 ID
- `wait()`
    - 阻塞当前进程, 直到某个子进程退出
    - 返回退出的子进程 ID
- `exec()`
    - 用一个新程序替换当前进程的代码段和数据段
    - 重新初始化堆区和栈区
- 如此奇怪的设计是为了方便在 `fork()` 与 `exec()` 之间插入其他操作, 如重定向标准输入输出

#### 受限直接执行

- 为了提高性能, 允许用户进程直接在 CPU 上运行, 但还是要受限于某些规则
- 区分用户态与内核态
- 提供陷入与从陷阱返回的硬件原语
    - 在每个进程的内核栈中保存现场
    - 内核在启动时设置陷阱表

#### 进程间切换

- 系统可以等待任意系统调用, 或者用户程序进行非法操作
    - `yield()` 什么也不做, 只是让出 CPU
- 也可以通过时钟中断, 时钟中断也就是为了操作系统维护控制权而设计的
    - 由操作系统启动时钟
    - 触发时会调用内核中的时钟中断处理程序
- 上下文切换
    - 和保存现场类似但不一样
    - 是由操作系统主导的存储在进程结构中的现场保存与恢复

#### 进程调度

- 越了解工作负载, 越能设计出好的调度算法
- $\text{周转时间} = \text{完成时间} - \text{到达时间}$ 性能指标
    - 性能和公平在调度中往往是矛盾的
- FIFO
    - 先到先工作
    - 出现长作业时, 短作业等待时间过长 (护航效应)
- SFJ 最短作业优先
    - 优先调度估计运行时间最短的作业
    - 需要预知作业运行时间, 实际中难以实现
- 现在考虑任务不同时间到达
- STCF 最短完成时间优先
    - 抢占式的 SJF
    - 新到达的短作业可以抢占正在运行的长作业
- $\text{响应时间} = \text{第一次运行时间} - \text{到达时间}$ 交互式系统重要指标
- RR 时间片轮转
    - 每个进程分配一个时间片, 时间片用完后切换到下一个进程
    - 时间片过大接近 FIFO, 过小则切换开销过大
    - 但对于周转时间非常差
- 现在考虑 IO 与运行时间不可知
- MLFQ 多级反馈队列
    - 基本思想
        - IO 密集型进程提升优先级, CPU 密集型进程降低优先级
        - 多个就绪队列, 每个队列有不同优先级, 队列内的进程优先级相同
        - 优先级高的队列先调度, 队列中进程采用 RR 调度
    - 方案
        - 新到达的进程进入最高优先级队列
        - 时间片用完后降低优先级, 但若在时间片内主动释放 CPU 则保持优先级
    - 对于 IO 密集型进程太友好, 可能导致 CPU 密集型进程饥饿
        - 每过一段时间, 将所有进程提升到最高优先级队列 (核心问题是具体多长时间)
    - 但是仍然会被恶意进程欺骗
        - 例如一个进程不断地在时间片内释放 CPU, 永远保持最高优先级
        - 解决方法是主动释放 CPU 不重置时间片
- 如果我们不考虑周转时间与响应时间, 而是确保每个工作获得一定比例的 CPU 时间
- 彩票调度
    - 每个进程根据彩票数量获得相应比例调度概率
    - 每次调度时, 系统随机抽取彩票, 持有该彩票的进程获得 CPU 时间
    - 彩票货币
        - 用户分配给进程彩票, 系统自动根据全局彩票池调度
    - 彩票转让
        - 进程可以将彩票转让给其他进程 (我依赖你, 我给你彩票)
    - 彩票通胀
        - 进程相互信任时, 可临时自发行彩票
    - 彩票中奖是随机的, 若为了公平性, 可引入行程, 使用步长调度
        - 用一个大数处以每个进程的彩票数, 结果作为该进程的步长
        - 每次调度一个进程时, 将该进程的行程加上步长
        - 每次调度时选择行程最小的进程

#### 多处理器调度

- 缓存亲和性: 尽可能将进程保持在同一个 CPU 上
- SQMS 单队列多处理器调度
    - 所有 CPU 共享一个就绪队列
    - 优点: 简单, 负载均衡
    - 缺点: 缓存亲和性差, 锁开销大
- MQMS 多队列多处理器调度
    - 每个 CPU 有自己的就绪队列
    - 优点: 缓存亲和性好, 锁开销小
    - 缺点: 负载均衡差 (但解决它的开销显著小于解决锁开销)
    - 解决方法
        - 迁移: 将某些进程从一个 CPU 队列迁移到另一个 CPU 队列
        - 具体实现为工作窃取: 空闲 CPU 从其他 CPU 窃取进程
- Linux 系统的实现, 三足鼎立
    - O(1) 调度器: 基于 MQMS + MLFQ
    - CFS 调度器: 基于 MQMS + 步长调度的 MLFQ
    - BFS 调度器: 基于 SQMS + EEVEF (最早最合适虚拟截止时间优先算法)

### 内存虚拟化

#### 地址空间

- 最早使用时分复用, 调度的进程才进入内存, 否则驻留在磁盘上
    - 太慢了, 所以内存够用的时候就不换出, 安全性又成问题
- 使用虚拟内存: 实现透明, 效率与保护
- `brk` 系统调用用来分配堆空间
    - 调整程序分断 (堆结束) 的位置

#### 地址转换

- 基于硬件的地址转换, 将虚拟地址转换为物理地址
- 需要解决的第一个问题, 如何将基于虚拟地址编写的程序载入到不同物理地址运行
- 动态重定位 (硬件实现, 对应的软件实现就是静态重定位)
    - 使用寄存器保存基址 (基址寄存器) 与界限 (界限寄存器)
    - 每次内存访问时, 将虚拟地址加上基址寄存器的值作为物理地址, 但虚拟地址不允许超过界限寄存器的值
    - 缺点: 只能实现连续分配, 内存碎片严重

#### 分段

- 栈与堆中间的内存未被使用, 导致大量浪费 (内部碎片)
- 考虑引入更多的基址与界限对, 每个分段一对
- 如何了解虚拟地址对应哪个分段
    - 将虚拟地址划分为两部分, 高位作为分段号, 低位作为段内偏移
    - 或者根据地址来源判断 (PC / 栈指针 / 其他)
- 栈在物理内存中也是向上增长的, 所以计算偏移量时要特殊处理
- 段也需要一个段表去维护权限, 基址与界限, 增长方向等信息
- 甚至堆空间的内部碎片也无法避免

#### 空闲空间管理

- 最初空闲列表 (链表) 维护空闲空间起始地址与大小, 不断分割与合并
    - 但是不能记录已分配空间的信息 (用于释放)
    - 链表节点本身就存储在空闲内存块内部, 不需要额外的内存 (`size` + `next`)
- 头块
    - 在每个分配块的前面存储一个头块, 记录该块的大小与魔法数 (完整性校验)
    - 返回给用户的指针是头块后面的地址
    - 被隐式创建, 使用, 释放, 用户不可见
- 使用 `mmap()` 或 `sbrk` 向操作系统申请内存
- 剩余空间不足时会尝试向操作系统申请更多内存, 还不够则返回 `NULL`
- 存在外部碎片问题, 尽可能优化分配算法
    - 最优分配: 分配最小的足够空间 (遍历开销大)
    - 最坏匹配: 分配最大的足够空间 (幻想避免产生过小碎片, 现实很骨感, 遍历开销大 + 没啥效果)
    - 首次匹配: 从头开始找到第一个足够空间 (速度快, 碎片更容易合并)
    - 循环首次匹配: 记录上次分配位置, 从该位置开始查找 (避免总是从头开始, 速度更快)
    - 厚块分配程序: 将空闲块按大小分类, 只在对应类别中查找 (减少遍历开销)
    - 伙伴算法: 将内存划分为若干 2 的幂次方大小的块, 分配时向上取整, 回收时合并相邻空闲块
- 现实中往往结合多种算法 + 使用更高级的数据结构 (如平衡树) 来管理空闲空间

#### 分页

- 部分见硬件软件接口
- 分段式将空间划分为若干不同大小的段, 分页式将空间划分为固定大小的页
- 页表设计
    - 多级页表
    - 每一项都是 $8$ 字节
    - 包括物理页号, 占 $40$ 位
    - 有效位, 缺不缺页
    - 读写位, 只能限制用户态
    - 特权位
    - 禁止执行位
    - 脏位, 是否被写过, 决定是否需要写回磁盘
        - 先于缓存的脏位, 写回磁盘前会先从缓存写回主存
    - 缓存位, 告诉 CPU 不用看 Cache 直接读写内存
    - 参考位, 是否被访问过, 用于页面置换算法
- 单级页表流程
    - 掩码 + 移位获得虚拟页号
    - 根据页表基址与虚拟页号计算页表项地址
    - 读取页表项, 物理页号 + 偏移量获得物理地址
    - 也就是翻倍的内存访问开销

#### TLB 与页表

- TLB 是页表的 Cache
    - 在 CPU 内部的内存管理单元实现, 速度非常快
    - 对其访问是纯硬件的, 操作系统配置一下页大小 (必须是 $2$ 的幂次方) 和页表位置即可
    - TLB 命中时直接拿到物理地址
    - TLB 失效时查页表, 再加载到 TLB
- TLB 表项
    - 虚拟页号
    - 物理页号
    - 保护位: 读 / 写 / 执行
    - 有效位: 表示缓存是否有效
    - ASID (地址空间标识符)
        - 用于区分不同进程的同一虚拟页号
        - 避免切换进程时清空 TLB 的开销
    - 脏位: 是否被写过
    - 全局位: 是否在所有进程中都有效 (忽略 ASID)
- 线性页表实在太大
    - 大页, 或者至少变长页
    - 分段 + 分页, 页表中只需要保存该段界限大小的地址空间的项
- 多级页表
    - 将页表划分为多级, 每级页表保存下一页表的地址
    - 只需要为使用的页分配页表项
    - 但增加了地址转换的内存访问开销
    - TLB 可以缓解这个问题
- 反向页表
    - 全局仅有一张页表, 每个页表项为一个物理页框
    - 每个项中保存该页框对应的虚拟页号与进程 ID
    - 通过哈希表建立索引

这篇文章详细介绍了现代操作系统（如 x86）中最常用的页表管理机制——**多级页表（Multi-Level Page Tables）**。

这部分内容是为了解决**线性页表（Linear Page Table）**面临的巨大内存浪费问题。为了让你彻底理解，我将文章拆解为核心痛点、工作原理、优缺点分析、具体计算实例以及硬件流程五个部分。

---

### 1. 核心痛点：线性页表太“胖”了

- **问题背景**：传统的线性页表是一个巨大的数组，涵盖了虚拟地址空间中的**每一个**可能的页。
- **现实情况**：大多数程序的内存使用是**稀疏（Sparse）**的。比如，使用了低地址的代码段，使用了高地址的栈，中间留着巨大的空白（未使用区域）。
- **浪费**：在线性页表中，即使中间几 GB 的空间完全没用，你也必须为它们保留页表项（标记为“无效”），这占用了大量连续的物理内存。
- **目标**：如何只为**正在使用**的内存分配页表，而扔掉那些无效区域的页表？

---

### 2. 解决方案：多级页表的树状结构

多级页表的核心思想是**“分页的分页”**，或者将其想象成一棵树。

#### 基本结构（两级为例）

1. **切分**：把巨大的线性页表切成一个个**页大小**的小块。
2. **按需分配**：
    - 如果某个小块里的**所有**页表项（PTE）都是无效的，那就**不分配**这个小块（不占用物理内存）。
    - 只有当小块里至少有一个有效的 PTE 时，才分配这个块。
3. **页目录（Page Directory, PD）**：
    - 既然页表被打散了，我们需要一个新的结构来记录这些小块都在哪里。这就是**页目录**。
    - 页目录由**页目录项（PDE）**组成。

#### 关键概念：PDE vs PTE

* **PTE (Page Table Entry)**：最底层的项，直接指向用户数据的物理页帧。
- **PDE (Page Directory Entry)**：指向一张**页表（Page Table）**。
- **PDE 的有效位（Valid Bit）**：含义发生了变化。
    - 如果 `PDE.Valid == 1`：表示它指向的那张页表已经分配在内存里了，里面至少有一个有效的页面映射。
    - 如果 `PDE.Valid == 0`：表示这一大块虚拟地址空间完全没被使用，对应的页表根本不存在。

---

### 3. 为什么多级页表更好？（以及代价）

这是系统设计中经典的**时空折中（Time-Space Trade-off）**。

#### 优势（Space & Management）

1. **节省内存**：只为有用的空间分配页表。对于稀疏地址空间，内存消耗极低。
2. **易于管理**：
    - 线性页表需要一大块**连续**的物理内存（例如 4MB 连续空间），这在内存碎片化时很难找到。
    - 多级页表将页表拆散成页大小（例如 4KB），**不需要连续的物理内存**。操作系统可以利用任意零散的空闲页来存放页表。

#### 劣势（Time & Complexity）

1. **变慢了（TLB 未命中时）**：
    - 线性页表：TLB 未命中 -> 读 1 次内存（查 PTE） -> 获取物理地址。
    - 两级页表：TLB 未命中 -> **读 2 次内存**（先查 PDE，再查 PTE） -> 获取物理地址。
    - *注：如果是 4 级页表（如 64位 x86），就要读 4 次内存！这就是为什么 TLB 如此重要。*
2. **复杂性**：硬件或操作系统遍历树状结构比简单的数组索引要复杂得多。

---

### 4. 详细实例解析（书中的数学题）

书中通过一个具体例子展示了地址转换过程，这里的位操作是理解的难点。

**环境设定**：
- 虚拟地址空间：16KB ($2^{14}$ 字节) -> **14 位地址**。
- 页大小：64 字节 ($2^6$ 字节) -> **6 位偏移量 (Offset)**。
- VPN 总位数：$14 - 6 = 8$ 位。

**构建页表结构**：
- PTE 大小：4 字节。
- 一页能装多少个 PTE？ $64 \text{ bytes} / 4 \text{ bytes} = 16$ 个 PTE。
- 索引 16 个 PTE 需要多少位？ $\log_2(16) = 4$ 位。
- **结论**：8 位的 VPN 被拆分为：
    - **高 4 位**：页目录索引（PDIndex）。
    - **低 4 位**：页表索引（PTIndex）。

**转换演示（地址 0x3F80）**：

1. **二进制**：`11 1111 1000 0000`
2. **拆分**：
    - `PDIndex` (高4位): `1111` (十进制 15)
    - `PTIndex` (次4位): `1110` (十进制 14)
    - `Offset` (低6位): `000000`
3. **查目录**：去页目录的第 15 项查找。假设 `PDE[15]` 有效且指向 PFN 101。
4. **查页表**：去物理页 101（这是页表页）的第 14 项查找。假设 `PTE[14]` 指向物理页帧 55。
5. **合成地址**：物理页 55 + 偏移量 0 -> 物理地址 `0x0DC0`。

---

### 5. 什么时候需要超过两级？

书中提到了一个重要逻辑：**如果页目录本身也大到超过一个页面怎么办？**

- **原则**：为了内存分配的灵活性，任何一级表的大小都不能超过一个物理页。
- **例子**：30 位地址，512 字节页大小。
    - 计算发现页目录需要 14 位索引，也就是 $2^{14}$ 个项，远超一页能容纳的数量。
- **解决**：**再加一级！** 将页目录再切分，上面再加一个“页目录的目录”。
    - 这构成了多级树（Page Directory Pointer -> Page Directory -> Page Table）。

---

### 6. 完整的硬件控制流（图 20.4）

这是全章的总结，展示了 CPU 访问内存的完整逻辑：

1. **第一步：查 TLB**
    - 这是最关键的一步。如果 TLB 命中（Hit），直接得到物理地址，**完全跳过**上面说的所有多级页表查找过程。性能极快。
2. **第二步：TLB 未命中（Miss）**
    - 硬件（或 OS）开始“爬树”。
    - 利用 VPN 高位 -> 找到 PDE -> 读内存。
    - 检查 PDE 是否有效？（无效则报 Segmentation Fault）。
    - 利用 VPN 次位 + PDE 里的 PFN -> 找到 PTE -> 读内存。
    - 检查 PTE 是否有效？
    - 获取最终 PFN，插入 TLB，重试指令。

### 总结

多级页表通过**增加查找层级（时间成本）**来换取**内存占用的显著减少（空间收益）**。它是现代操作系统能够支持 64 位巨大地址空间（大部分是空的）而不耗尽物理内存的关键技术。而 **TLB** 的存在掩盖了多级查找带来的性能开销。

## 并发控制

## 持久化
